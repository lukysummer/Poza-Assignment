{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## install dependencies\n",
        "\n",
        "magenta 와 music_vae libraries 들을 import 하고 사용할 때 필요한 dependencies."
      ],
      "metadata": {
        "id": "aLjPlbe2qesl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq && apt-get install -qq libfluidsynth2 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -q pyfluidsynth"
      ],
      "metadata": {
        "id": "8yKKuHC7Dmrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install my **forked** magenta package"
      ],
      "metadata": {
        "id": "YyTwwM9EqjUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QL6-0DuGDg53"
      },
      "outputs": [],
      "source": [
        "!pip install -qU -e git+https://github.com/lukysummer/magenta.git#egg=magenta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAKE SURE TO RESTART AFTER RUNNING THE ABOVE CELL !!!**"
      ],
      "metadata": {
        "id": "SlMxP_19Di4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with forked package and new config `groovae_4bar_MusicVAE`"
      ],
      "metadata": {
        "id": "OjCKE02Tq2tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/magenta/magenta/tree/main/magenta/models/music_vae#training-your-own-musicvae\n",
        "!music_vae_train \\\n",
        "--config=groovae_4bar_MusicVAE \\\n",
        "--run_dir=groove_music_vae/ \\\n",
        "--mode=train \\\n",
        "--tfds_name=groove/4bar-midionly \\\n",
        "--hparams=learning_rate=0.0005"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c6NhyjznNNIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample with trained checkpoints\n",
        "\n"
      ],
      "metadata": {
        "id": "JI6g6ViBuw0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample with checkpoints at different steps to compare\n",
        "\n",
        "To check if there is any improvement as training progress."
      ],
      "metadata": {
        "id": "efYHM2Z2_aBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_ckpt_dir = \"groove_music_vae/train\"  # directory where all checkpoints during training are saved.\n",
        "sample_save_dir = \"generated_samples\"      # directory to save generated samples\n",
        "\n",
        "# Create the directory to save generated samples.\n",
        "if not os.path.exists(sample_save_dir):\n",
        "  os.mkdir(sample_save_dir)"
      ],
      "metadata": {
        "id": "Sf3SWcJ9C58A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv test/* groove_music_vae/train/"
      ],
      "metadata": {
        "id": "pjROfSjYDyy4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "from typing import List\n",
        "\n",
        "def generate(ckpt_path: str, # checkpoint path to use for sampling\n",
        "             config_name: str, # name of the config to use for sampling\n",
        "             n_samples: int, # Number of samples to generate\n",
        "             n_16th_notes: int, # Number of 16th notes to generate (= Number of bars to generate * 4)\n",
        "             temperature: float, # degree of randomness between 0 and 1 (1: no randomness)\n",
        "             save_sample: bool = False, # whether or not to save generated sample(s)\n",
        "             sample_save_dir: str = \"\", # path to generated sample(s) if save_sample=True\n",
        "             ):  \n",
        "  # Create a TrainedModel instance.\n",
        "  loaded_model = TrainedModel(configs.CONFIG_MAP[config_name], batch_size=4, checkpoint_dir_or_path=ckpt_path)\n",
        "\n",
        "  # Generate `n_samples` note sequences with the current checkpoint.\n",
        "  drum_samples = loaded_model.sample(n=n_samples, \n",
        "                                     length=n_16th_notes, \n",
        "                                     temperature=temperature)\n",
        "  \n",
        "  # For each of the `n_samples` generated note sequence,\n",
        "  for i, ns in enumerate(drum_samples):\n",
        "    # Play generated note sequence.\n",
        "    mm.play_sequence(ns, synth=mm.fluidsynth)\n",
        "\n",
        "    # Convert the generated note sequence into a midi file and save to `sample_save_dir`.\n",
        "    midi_out_path = os.path.join(sample_save_dir, f\"step_{test_step}_sample_{i}.mid\")\n",
        "    mm.sequence_proto_to_midi_file(ns, midi_out_path)"
      ],
      "metadata": {
        "id": "u0zkxtkaKlUR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of training step numbers to generate samples from\n",
        "steps_to_test=[1345, 18257, 27518, 36656, 47527, 57773] \n",
        "\n",
        "for test_step in steps_to_test:\n",
        "  print(\"----------------------------------\")\n",
        "  print(f\"Now testing checkpoint at step {test_step}\")\n",
        "\n",
        "  # Define checkpoint path.\n",
        "  ckpt_path = os.path.join(train_ckpt_dir, f\"model.ckpt-{test_step}\")\n",
        "\n",
        "  # Generate samples.\n",
        "  generate(ckpt_path=ckpt_path, config_name='groovae_4bar_MusicVAE',\n",
        "           n_samples=4, n_16th_notes=16*4, temperature=0.5,\n",
        "           save_sample=True, sample_save_dir=sample_save_dir)"
      ],
      "metadata": {
        "id": "7FwxK3R6yhSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip and download generated files\n",
        "!zip -qq -r generated_samples.zip generated_samples\n",
        "from google.colab import files\n",
        "files.download(\"generated_samples.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TBobC1fNFa65",
        "outputId": "1cdca136-f2a4-434a-979b-875ddabe8970"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3353c35e-222c-490c-be09-9e4ce407b6da\", \"generated_samples.zip\", 9157)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try sampling with other models for comparison\n",
        "\n",
        "Using pre-trained checkpoints available in [Music VAE Github](https://github.com/magenta/magenta/tree/master/magenta/models/music_vae)"
      ],
      "metadata": {
        "id": "ff3XlhJ90J7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n",
        "\n",
        "# For example, use the pre-trained checkpoint trained with 2-bar drums with 9 classes.\n",
        "generate(ckpt_path=BASE_DIR + '/checkpoints/drums_2bar_small.lokl.ckpt', \n",
        "         config_name='cat-drums_2bar_small',\n",
        "         n_samples=4, n_16th_notes=16*4, temperature=0.5)"
      ],
      "metadata": {
        "id": "sm37bn1OQsLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}